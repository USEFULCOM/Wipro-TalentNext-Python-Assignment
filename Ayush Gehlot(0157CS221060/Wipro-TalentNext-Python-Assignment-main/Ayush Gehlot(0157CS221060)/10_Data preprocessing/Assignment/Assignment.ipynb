{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Mini-Project: Melbourne Housing Data Preprocessing üè°\n",
    "\n",
    "This notebook provides a complete, working solution for preprocessing the `melb_data.csv` dataset. It uses both Pandas for data loading/manipulation and Scikit-learn for encoding, covering both of your assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the Data (Using Pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('melb_data.csv')\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(\"Original shape:\", df.shape)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Handle Missing Data (Using Pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Handling Missing Data ---\")\n",
    "print(\"Missing values before handling:\\n\", df.isnull().sum().sort_values(ascending=False).head())\n",
    "\n",
    "# Strategy: Fill numerical columns with the median and categorical columns with the mode.\n",
    "for col in df.columns:\n",
    "    if df[col].isnull().any():\n",
    "        if pd.api.types.is_object_dtype(df[col]):\n",
    "            df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "        else:\n",
    "            df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "print(\"\\nTotal missing values after handling:\", df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Handle Categorical Data (Using a mix of Pandas and Scikit-learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Handling Categorical Data ---\")\n",
    "df_processed = df.copy()\n",
    "\n",
    "# Using Pandas get_dummies for columns with low cardinality\n",
    "low_cardinality_cols = [col for col in df_processed.select_dtypes(include='object').columns if df_processed[col].nunique() < 10]\n",
    "df_processed = pd.get_dummies(df_processed, columns=low_cardinality_cols, drop_first=True)\n",
    "print(f\"Applied One-Hot Encoding on: {low_cardinality_cols}\")\n",
    "\n",
    "# Using Scikit-learn's LabelEncoder for columns with high cardinality\n",
    "label_encoder = LabelEncoder()\n",
    "high_cardinality_cols = [col for col in df_processed.select_dtypes(include='object').columns if df_processed[col].nunique() >= 10]\n",
    "for col in high_cardinality_cols:\n",
    "    df_processed[col] = label_encoder.fit_transform(df_processed[col])\n",
    "print(f\"Applied Label Encoding on: {high_cardinality_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Complete ‚úÖ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final shape of the processed dataset:\", df_processed.shape)\n",
    "print(\"First 5 rows of the processed dataset:\")\n",
    "display(df_processed.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}